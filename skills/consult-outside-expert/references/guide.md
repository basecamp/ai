# Consult Outside Expert Guide

Consult an outside expert to collaboratively refine work through iterative back-and-forth. The goal is convergence on excellent outcomes through multiple perspectives, not consensus for its own sake.

---

## Core Principle

The loop is: Review -> Mediate -> Improve -> Repeat (review updated artifact). The mediator enforces quality gates and convergence.

An expert is not a judge. An expert is a signal generator. The mediator owns synthesis and decisions.

---

## Severity Rubric

All experts must use this shared scale:

| Severity | Definition | Gate impact |
|----------|------------|-------------|
| **High** | Blocks shipping. Incorrect, unsafe, or fundamentally broken. | Must fix before close. |
| **Medium** | Should fix. Quality/maintainability issue but not blocking. | Fix or explicitly accept risk. |
| **Low** | Nice to have. Polish, style, minor improvements. | Fix if time permits. |

Experts label findings with H/M/L. The mediator uses these to enforce gates.

---

## Roles

- **Implementer**: the agent doing the work. Also does self-review (see Dual-Review Pattern). Proposes synthesis artifacts but does not approve design decisions.
- **Mediator**: you (the human). You set scope, approve synthesis, reconcile disagreements, and decide what changes. All design decisions require your explicit approval.
- **Expert(s)**: independent external experts with distinct lenses.

**Critical:** The implementer must STOP and escalate to the mediator - not proceed autonomously - when design decisions arise. The implementer writes synthesis proposals; the mediator owns final decisions.

Expert lenses you can assign:
- Correctness expert (accuracy, risks, edge cases)
- Design/architecture expert (structure and tradeoffs)
- User-impact expert (UX, clarity, ergonomics)
- Testing expert (coverage, verification)
- Red team expert (failure modes, adversarial thinking)
- Domain expert (subject matter depth)

---

## Modes

### Multi-agent mode (2-4 experts)
The full ping-pong with multiple perspectives. Use when:
- High-stakes artifact
- Complex tradeoffs
- Need diverse lenses

### Two-agent mode (implementer + 1 expert)
The common case. One implementer, one outside expert. Use when:
- Iterating quickly
- Single dominant concern (e.g., correctness)
- Limited time

In two-agent mode:
- "Disagreements" captures self-review vs external review conflicts (not skipped - dual-review still produces potential disagreements)
- Convergence: use Phase 3 conditions (same as multi-agent)
- The external expert IS the outside expert

---

## Orchestration

Choose how you run the loop:

### Manual log (copy/paste)
Use `review-log.md` and paste expert responses each round. This is the default and is fully checkable with the eval checks.

### MCP thread (Codex)
If you have Codex MCP available (`mcp__codex__codex` and `mcp__codex__codex-reply` tools), you can run the expert through a single MCP thread and avoid manual copy/paste. Create `review-session.md` and record the thread ID plus round summaries so the loop is auditable.

**Note:** MCP mode is optimized for two-agent mode (one expert). For multi-agent reviews, use manual mode or run multiple MCP threads (one per expert lens).

**Prerequisite:** Codex MCP server configured. See `codex mcp-server --help` for setup.

---

## Phase 1: Setup (Gate)

Define the review contract before any review happens.

### Inputs
- Artifact to review (code diff, plan, doc, spec)
- Scope boundaries (what is in/out)
- Quality bar (what "S-tier" means here)
- Time budget (rounds or minutes)

### Reviewer roster
- **Multi-agent mode**: Pick 2-4 experts with different lenses. Ensure at least one is a outside expert.
- **Two-agent mode**: One outside expert. That's it.

### Create a session record
Pick one:
- **Manual log:** Create `review-log.md` in the working directory. Use the template below so checks can be run.
- **MCP thread:** Create `review-session.md` and record the thread ID. Use the template below.

**Gate to proceed:**
- Artifact and scope are stated
- Reviewers and lenses are selected
- `review-log.md` or `review-session.md` exists

---

## The Dual-Review Pattern (Default)

The implementer is not just a fixer - they are also an evaluator. Every round follows this pattern:

1. **Implementer self-reviews** - Before external review, the implementer examines their own work with fresh eyes. Produce H/M/L findings just like an external expert would.
2. **External expert(s) review independently** - For Round 1, do not share self-review or other experts' feedback with external experts. Each expert produces findings independently. In later rounds, sharing the synthesis is fine - experts need to know what changed and why. The independence requirement is about getting unbiased initial signal, not about keeping experts in the dark about iteration history.
3. **Reconcile** - Compare both sets of findings. Where do they agree? Where do they disagree? Steelman both perspectives.
4. **Present decision points** - When reconciliation surfaces design tradeoffs, present them to the mediator via AskUserQuestion or text template.
5. **Implement** - Address agreed actions.

This pattern prevents "outsourcing" review to external agents. The implementer must engage critically with their own work first.

---

## Phase 2: Round Loop

Each round has four steps: Self-Review, External Review, Reconcile, Synthesize.

**Between rounds:** After synthesis is approved, the implementer does the work. The next round opens with `### Changes` documenting what was done, then reviews the updated artifact.

### Step 0: Self-Review
Before sending to external experts, the implementer reviews their own work:
- Examine the artifact with a critical lens
- Produce findings with H/M/L severity labels
- Be genuinely critical - don't softball yourself

### Step A: External Review
Send each external expert a brief with constraints and required output structure.

Reviewer brief template:
```
ROLE: [Reviewer lens]
TASK: Review the artifact for [goal].
SCOPE: [in scope] / [out of scope]
CONSTRAINTS:
- For Round 1: Review independently - do not read self-review or other experts' feedback first
- Be specific and actionable
- Avoid repeats unless you add new evidence
- If you disagree with another expert, say why

OUTPUT FORMAT:
1) Findings (ordered, severity-labeled)
2) Risks / missing considerations
3) Tests / verification
4) Suggested changes
5) Confidence (low/medium/high)
```

### MCP option: Reviewer thread
If using Codex MCP, start the expert in a single thread and reuse it across rounds:

Round 1 (start new thread):
```
mcp__codex__codex(prompt="You are the outside expert... [artifact path] [scope] [quality bar] [output format]", cwd="...") -> threadId
```

Round N (reuse thread):
```
mcp__codex__codex-reply(threadId="...", prompt="Here is the updated artifact, changes made, and synthesis from Round N-1: [include key decisions, risks accepted]. Provide deltas only (H/M/L labeled) - no repeats from previous rounds.")
```

Record `threadId` and round summaries in `review-session.md`.

### Step B: Reconcile and Propose Synthesis
The implementer synthesizes self-review + external review into a single decision artifact. The mediator (human) reviews and approves before proceeding.

Synthesis proposal template (implementer writes, mediator approves):
```
### Round N Synthesis

**Consensus:**
- ...

**Disagreements:** (self-review vs external, or between external experts)
- [Reviewer/Source] vs [Reviewer/Source]: [topic]
  - Decision: [what we do and why]

**Actions:**
- [ ] Action 1 (owner: implementer)
- [ ] Action 2

**Decision points:** none this round.
(or full DECISION POINT template if triggers fired)

**Open Questions:**
- ...

**Gate Status:**
- Open high-severity items? [yes/no - must be no to close]
- Open medium items accepted? [yes/no/N/A]
- All actions addressed? [yes/no]
- Ready to close? [yes/no]

**Mediator Approval:** pending
```
(When mediator gives approval, replace "pending" with "approved by NAME")

### Between Rounds: Implement
After synthesis is approved, the implementer addresses agreed actions before the next round begins.

- Implementer addresses actions from synthesis
- Next round opens with `### Changes (Round N)` documenting what was done
- Gate: Changes logged at start of next round (check #6: count = rounds - 1)

**STOP for escalation** if any action involves:

| Trigger | Action |
|---------|--------|
| Design tradeoff | Present options A/B with pros/cons |
| "By design" response | Don't dismiss - escalate to mediator |
| Scope change | Confirm before proceeding |
| Repeated issue (2+ rounds) | May indicate deeper problem |
| Accepting limitation | Mediator decides, not implementer |
| Architectural choice | Affects overall structure |

**When triggers fire** - STOP and present decision:

**Option 1: AskUserQuestion tool** (Claude Code)
```
AskUserQuestion({
  questions: [{
    question: "[Issue]? Stake: [what gets worse if wrong]",
    header: "Design",
    options: [
      { label: "Option A (Recommended)", description: "[approach] - Pro: X, Con: Y" },
      { label: "Option B", description: "[approach] - Pro: X, Con: Y" }
    ],
    multiSelect: false
  }]
})
```

**Option 2: Text template** (portable fallback)
```
DECISION POINT: [issue]
Stake: [what gets worse if we choose wrong]

Option A: [approach]
- Pro: ...
- Con: ...

Option B: [approach]
- Pro: ...
- Con: ...

Recommendation: [A/B] because [reasoning]

Your call?
```

Wait for explicit response before proceeding. Log: `Approved: [decision] by [user]`

**When no triggers fire** - state explicitly in synthesis:
```
Decision points: none this round.
```

This creates an auditable trace that the agent checked. Silence cannot masquerade as compliance.

**Discretion expected.** The trigger list is intentionally tight. Don't escalate every minor choice - that defeats the purpose too. Escalate design tradeoffs that shape the outcome. When in doubt, escalate - it's better to over-communicate than to make unilateral design decisions.

### Starting the Next Round
When beginning Round N+1, send targeted follow-ups. Ask for deltas on the updated artifact, not repeats.

Ping-back prompt:
```
Here is the updated artifact, what changed, and the synthesis from the previous round.

[Include: changes made, key decisions, any risks accepted]

Respond with:
- Any critical misses (H/M/L labeled)
- Any disagreement with the decisions made
- Any new issues (H/M/L labeled) - prioritize H/M, but don't suppress M issues
No repeats from previous rounds. Use H/M/L severity labels.
```

**Round gate:**
- Each expert response uses H/M/L severity labels
- Synthesis includes Consensus, Disagreements, Actions, Gate Status
- Changes logged at start of round (for rounds > 1)

---

## Phase 3: Convergence Gate

Stop when the loop converges. Use one of these stop conditions:
- Two consecutive rounds with no open high-severity items (not just "no new" - all H issues must be resolved) AND all Medium issues either fixed or explicitly accepted by mediator
- No open H issues, all actions addressed, experts have no new deltas, AND all Medium issues either fixed or explicitly accepted
- Time budget reached and risk is explicitly accepted by the mediator (not self-approved by implementer) - must document which H/M issues remain and why

**Close-out artifact:** A final synthesis with decisions, next steps, and human attestation.

**Required attestation:** The mediator must include:
```
**Attestation:** I confirm this log reflects genuine review work, not template filling. - [NAME]
```
This creates accountability that automated checks cannot provide. Eval checks are smoke tests; attestation is the real gate.

**Note:** The attestation is human accountability, not automated enforcement. If someone lies in their attestation, that's fraud - the system worked, the human failed. The check only verifies the field exists and isn't obviously a placeholder.

---

## Drop Criteria (Reviewer Pruning)

Drop an expert when:
- They repeat prior points without new evidence
- Their feedback is consistently non-actionable
- They fail to follow the format twice
- They lower the quality bar (overly lenient)

If dropped, document why in the log.

**Important:** In two-agent mode, if you drop the only external expert, you must either:
1. Replace them with another external expert, OR
2. Escalate to mediator to decide how to proceed

Never continue with self-review only - the External Review per round eval check will fail.

---

## Eval Checks

Choose the checks based on orchestration mode.

**Note:** Count-based checks (rounds, actions, changes) print values for human verification. Pass/fail is manual - compare counts against expected values.

### Manual log checks (`review-log.md`)

| # | Check | Command | Pass |
|---|-------|---------|------|
| 1 | Log exists | `test -f review-log.md` | File exists |
| 2 | Each round has synthesis | `grep -c "^### Round .* Synthesis" review-log.md` | Count ≥ 1 |
| 3 | Synthesis has required sections | `grep -E "^\*\*(Consensus|Disagreements|Actions|Gate Status):" review-log.md` | All 4 present per round |
| 4 | H/M/L findings captured | `grep -qE "(^|[[:space:]-])([HML]:|High:|Medium:|Low:)" review-log.md` | Exit 0 |
| 5 | Gate Status per round | `grep -c "^\*\*Gate Status:" review-log.md` | Count = rounds |
| 6 | Changes logged (if round > 1) | `grep -c "^### Changes" review-log.md` | Count = rounds - 1 |
| 7 | Decision points addressed | `grep -qE "Decision points:|DECISION POINT:" review-log.md` | Exit 0 |
| 8 | Approvals logged (if decisions) | See script below | Exit 0 |
| 9 | Decision points per round | See script below | Rounds = traces |
| 10 | Self-Review per round | `grep -c "^### Self-Review" review-log.md` | Count = rounds |
| 11 | External Review per round | `grep -c "^### External Review" review-log.md` | Count = rounds |
| 12 | Reconciliation per round | `grep -c "^### Reconciliation" review-log.md` | Count = rounds |
| 13 | Mediator approval per round | `grep -cE "^\*\*Mediator Approval:\*\* approved by [^[]" review-log.md` | Count = rounds |
| 14 | Final synthesis exists | `grep -q "^## Final Synthesis" review-log.md` | Exit 0 |
| 15 | Attestation present | `grep -qE "^\*\*Attestation:\*\*.+- [^[]" review-log.md` | Exit 0 |
| 16 | Disagreements per round | `grep -c "^\*\*Disagreements:" review-log.md` | Count = rounds |

```bash
# Quick check script
echo "1) Log exists:"
test -f review-log.md && echo "PASS" || echo "FAIL"

echo "2) Synthesis blocks:"
grep -c "^### Round .* Synthesis" review-log.md || echo "0"

echo "3) Required sections (expect 4 per round):"
grep -E "^\*\*(Consensus|Disagreements|Actions|Gate Status):" review-log.md | wc -l

echo "4) H/M/L findings:"
grep -qE "(^|[[:space:]-])([HML]:|High:|Medium:|Low:)" review-log.md && echo "PASS" || echo "FAIL"

echo "5) Gate Status per round:"
grep -c "^\*\*Gate Status:" review-log.md || echo "0"

echo "6) Changes logged:"
grep -c "^### Changes" review-log.md || echo "0"

echo "7) Decision points addressed:"
grep -qE "Decision points:|DECISION POINT:" review-log.md && echo "PASS" || echo "FAIL"

echo "8) Approvals logged (if decisions):"
# Check if any decision point is NOT "none this round"
if grep -E "Decision points:|DECISION POINT:" review-log.md | grep -qv "none this round"; then
  # Require "Approved:" followed by non-bracket content (not placeholder text)
  grep -qE "Approved: [^[]" review-log.md && echo "PASS" || echo "FAIL (decision without approval)"
else
  echo "PASS (no decisions)"
fi

echo "9) Decision points per round:"
rounds=$(grep -c "^## Round" review-log.md || echo 0)
# Count either "Decision points:" (no triggers) or "DECISION POINT:" (triggers fired)
dpoints=$(grep -cE "Decision points:|DECISION POINT:" review-log.md || echo 0)
[ "$rounds" -eq "$dpoints" ] && echo "PASS ($rounds rounds, $dpoints traces)" || echo "WARN: $rounds rounds, $dpoints decision point traces"

echo "10) Self-Review per round:"
selfreviews=$(grep -c "^### Self-Review" review-log.md || echo 0)
[ "$rounds" -eq "$selfreviews" ] && echo "PASS ($selfreviews self-reviews)" || echo "WARN: $rounds rounds, $selfreviews self-reviews"

echo "11) External Review per round:"
extreviews=$(grep -c "^### External Review" review-log.md || echo 0)
[ "$rounds" -eq "$extreviews" ] && echo "PASS ($extreviews external reviews)" || echo "WARN: $rounds rounds, $extreviews external reviews"

echo "12) Reconciliation per round:"
reconciliations=$(grep -c "^### Reconciliation" review-log.md || echo 0)
[ "$rounds" -eq "$reconciliations" ] && echo "PASS ($reconciliations reconciliations)" || echo "WARN: $rounds rounds, $reconciliations reconciliations"

echo "13) Mediator approval per round:"
approvals=$(grep -cE "^\*\*Mediator Approval:\*\* approved by [^[]" review-log.md || echo 0)
[ "$rounds" -eq "$approvals" ] && echo "PASS ($approvals approvals)" || echo "WARN: $rounds rounds, $approvals mediator approvals"

echo "14) Final synthesis:"
grep -q "^## Final Synthesis" review-log.md && echo "PASS" || echo "FAIL"

echo "15) Attestation (THE REAL GATE):"
grep -qE "^\*\*Attestation:\*\*.+- [^[]" review-log.md && echo "PASS" || echo "FAIL (missing human attestation)"

echo "16) Disagreements per round:"
disagreements=$(grep -c "^\*\*Disagreements:" review-log.md || echo 0)
[ "$rounds" -eq "$disagreements" ] && echo "PASS ($disagreements disagreement sections)" || echo "WARN: $rounds rounds, $disagreements disagreement sections"
```

### MCP session checks (`review-session.md`)

| # | Check | Command | Pass |
|---|-------|---------|------|
| 1 | Session exists | `test -f review-session.md` | File exists |
| 2 | Thread ID recorded | `grep -q "^Thread ID:" review-session.md` | Exit 0 |
| 3 | At least one round | `grep -c "^## Round" review-session.md` | Count ≥ 1 |
| 4 | Rounds have gate status | `grep -c "^\*\*Gate Status:" review-session.md` | Count = rounds |
| 5 | H/M/L findings captured | `grep -qE "(^|[[:space:]-])([HML]:|High:|Medium:|Low:)" review-session.md` | Exit 0 |
| 6 | Changes logged (if round > 1) | `grep -c "^### Changes" review-session.md` | Count = rounds - 1 |
| 7 | Decision points addressed | `grep -qE "Decision points:|DECISION POINT:" review-session.md` | Exit 0 |
| 8 | Approvals logged (if decisions) | See script below | Exit 0 |
| 9 | Decision points per round | See script below | Rounds = traces |
| 10 | Self-Review per round | `grep -c "^### Self-Review" review-session.md` | Count = rounds |
| 11 | External Review per round | `grep -c "^### External Review" review-session.md` | Count = rounds |
| 12 | Reconciliation per round | `grep -c "^### Reconciliation" review-session.md` | Count = rounds |
| 13 | Mediator approval per round | `grep -cE "^\*\*Mediator Approval:\*\* approved by [^[]" review-session.md` | Count = rounds |
| 14 | Final synthesis exists | `grep -q "^## Final Synthesis" review-session.md` | Exit 0 |
| 15 | Attestation present | `grep -qE "^\*\*Attestation:\*\*.+- [^[]" review-session.md` | Exit 0 |
| 16 | Disagreements per round | `grep -c "^\*\*Disagreements:" review-session.md` | Count = rounds |
| 17 | Synthesis has required sections | `grep -E "^\*\*(Consensus|Disagreements|Actions|Gate Status):" review-session.md` | All 4 present per round |

```bash
# Quick check script (MCP)
echo "1) Session exists:"
test -f review-session.md && echo "PASS" || echo "FAIL"

echo "2) Thread ID:"
grep -q "^Thread ID:" review-session.md && echo "PASS" || echo "FAIL"

echo "3) Round count:"
grep -c "^## Round" review-session.md || echo "0"

echo "4) Gate status per round:"
grep -c "^\*\*Gate Status:" review-session.md || echo "0"

echo "5) H/M/L findings:"
grep -qE "(^|[[:space:]-])([HML]:|High:|Medium:|Low:)" review-session.md && echo "PASS" || echo "FAIL"

echo "6) Changes logged:"
grep -c "^### Changes" review-session.md || echo "0"

echo "7) Decision points addressed:"
grep -qE "Decision points:|DECISION POINT:" review-session.md && echo "PASS" || echo "FAIL"

echo "8) Approvals logged (if decisions):"
# Check if any decision point is NOT "none this round"
if grep -E "Decision points:|DECISION POINT:" review-session.md | grep -qv "none this round"; then
  # Require "Approved:" followed by non-bracket content (not placeholder text)
  grep -qE "Approved: [^[]" review-session.md && echo "PASS" || echo "FAIL (decision without approval)"
else
  echo "PASS (no decisions)"
fi

echo "9) Decision points per round:"
rounds=$(grep -c "^## Round" review-session.md || echo 0)
# Count either "Decision points:" (no triggers) or "DECISION POINT:" (triggers fired)
dpoints=$(grep -cE "Decision points:|DECISION POINT:" review-session.md || echo 0)
[ "$rounds" -eq "$dpoints" ] && echo "PASS ($rounds rounds, $dpoints traces)" || echo "WARN: $rounds rounds, $dpoints decision point traces"

echo "10) Self-Review per round:"
selfreviews=$(grep -c "^### Self-Review" review-session.md || echo 0)
[ "$rounds" -eq "$selfreviews" ] && echo "PASS ($selfreviews self-reviews)" || echo "WARN: $rounds rounds, $selfreviews self-reviews"

echo "11) External Review per round:"
extreviews=$(grep -c "^### External Review" review-session.md || echo 0)
[ "$rounds" -eq "$extreviews" ] && echo "PASS ($extreviews external reviews)" || echo "WARN: $rounds rounds, $extreviews external reviews"

echo "12) Reconciliation per round:"
reconciliations=$(grep -c "^### Reconciliation" review-session.md || echo 0)
[ "$rounds" -eq "$reconciliations" ] && echo "PASS ($reconciliations reconciliations)" || echo "WARN: $rounds rounds, $reconciliations reconciliations"

echo "13) Mediator approval per round:"
approvals=$(grep -cE "^\*\*Mediator Approval:\*\* approved by [^[]" review-session.md || echo 0)
[ "$rounds" -eq "$approvals" ] && echo "PASS ($approvals approvals)" || echo "WARN: $rounds rounds, $approvals mediator approvals"

echo "14) Final synthesis:"
grep -q "^## Final Synthesis" review-session.md && echo "PASS" || echo "FAIL"

echo "15) Attestation (THE REAL GATE):"
grep -qE "^\*\*Attestation:\*\*.+- [^[]" review-session.md && echo "PASS" || echo "FAIL (missing human attestation)"

echo "16) Disagreements per round:"
disagreements=$(grep -c "^\*\*Disagreements:" review-session.md || echo 0)
[ "$rounds" -eq "$disagreements" ] && echo "PASS ($disagreements disagreement sections)" || echo "WARN: $rounds rounds, $disagreements disagreement sections"

echo "17) Required sections (expect 4 per round):"
grep -E "^\*\*(Consensus|Disagreements|Actions|Gate Status):" review-session.md | wc -l
```

If any check fails, fix the log structure before proceeding.

---

## Failure Modes

| Symptom | Cause | Fix |
|---|---|---|
| Reviewers keep repeating | No delta-only constraint | Add ping-back rule, enforce no repeats |
| Convergence stalls | Disagreements not mediated | Force explicit decisions in synthesis |
| Low signal feedback | Wrong expert lens | Replace or re-brief expert |
| Too many issues, no action | Missing prioritization | Rank by severity and cut scope |
| Reviewer contradicts themselves | No evidence requirement | Ask for evidence or drop |
| MCP session lost | Thread ID not recorded | Record in `review-session.md` and restate context |
| Implementer steamrolls decisions | Not escalating tradeoffs | Review escalation triggers, re-examine "by design" calls |
| "By design" used defensively | Avoiding work vs genuine tradeoff | Mediator must approve all "by design" responses |
| Fast convergence, wrong outcome | Implementer and expert aligned but wrong | Human mediator validates key decisions, not just pass/fail |
| Eval checks pass on placeholder text | Template text contains patterns that match checks | Use negated character classes like `[^[]` to reject bracket placeholders |
| Terse expert prompts produce shallow feedback | Bare "You are a outside expert" lacks context | Use rich prompts establishing role, relationship, expertise, collaborative framing |
| Checks pass but no real work done | Eval checks are smoke tests, not proof of work | Require human attestation in final synthesis - the real gate |
| Round 1 external review echoes self-review | Self-review was shared before initial external review | Keep Round 1 reviews independent - share synthesis only in later rounds |

---

## Working Log Template

Create `review-log.md` and append per round.

```
# Review Log

## Artifact
- Description: ...
- Scope: ...
- Quality bar: ...

## Reviewers
- Reviewer A: [lens]
(two-agent mode: just one expert)

---

## Round 1

### Self-Review (Implementer)
[Implementer's own findings with H/M/L severity labels]
- H: ...
- M: ...
- L: ...

### External Review (Reviewer A)
[Paste response with H/M/L severity labels]

### Reconciliation
| Issue | Self-Review | External | Agreement |
|-------|-------------|----------|-----------|
| ... | Found/Missed | Found/Missed | Agree/Disagree |

### Round 1 Synthesis

**Consensus:**
- ...

**Disagreements:**
- ...

**Actions:**
- [ ] ...

**Decision points:** none this round.
(or DECISION POINT template + "Approved: [decision] by [user]")

**Open Questions:**
- ...

**Gate Status:**
- Open high-severity items? [yes/no - must be no to close]
- Open medium items accepted? [yes/no/N/A]
- All actions addressed? [yes/no]
- Ready to close? [yes/no]

**Mediator Approval:** pending

---

## Round 2

### Changes (Round 1)
- [What was implemented from Round 1 actions]

### Self-Review (Implementer)
[Implementer's own review of changes with H/M/L]

### External Review (Reviewer A)
[Paste delta-only response with H/M/L labels]

### Reconciliation
| Issue | Self-Review | External | Agreement |
|-------|-------------|----------|-----------|

### Round 2 Synthesis

**Consensus:**
- ...

**Disagreements:**
- ...

**Actions:**
- [ ] ...

**Decision points:** none this round.

**Gate Status:**
- Open high-severity items? [yes/no - must be no to close]
- Open medium items accepted? [yes/no/N/A]
- All actions addressed? [yes/no]
- Ready to close? [yes/no]

**Mediator Approval:** pending

---

## Final Synthesis
- Decision: ...
- Risks accepted: ...
- Next steps: ...

**Attestation:** I confirm this log reflects genuine review work, not template filling. - [NAME]
```

---

## MCP Session Template

Create `review-session.md` if using Codex MCP. Must capture same gates as manual mode.

```
# Review Session

## Artifact
- Description: ...
- Scope: ...
- Quality bar: ...

## Reviewers
- Reviewer A: [lens] (Codex MCP)

Thread ID: [from mcp__codex__codex response]

---

## Round 1

### Self-Review (Implementer)
[Implementer's own findings with H/M/L severity labels]
- H: ...
- M: ...
- L: ...

### External Review (Codex)
[Paste or summarize Codex response - must include H/M/L labels]
- H: ...
- M: ...
- L: ...

### Reconciliation
| Issue | Self-Review | Codex | Agreement |
|-------|-------------|-------|-----------|
| ... | Found/Missed | Found/Missed | Agree/Disagree |

### Round 1 Synthesis

**Consensus:**
- ...

**Disagreements:**
- ...

**Actions:**
- [ ] ...

**Decision points:** none this round.
(or full DECISION POINT template if triggers fired, with "Approved: [decision] by [user]")

**Open Questions:**
- ...

**Gate Status:**
- Open high-severity items? [yes/no - must be no to close]
- Open medium items accepted? [yes/no/N/A]
- All actions addressed? [yes/no]
- Ready to close? [yes/no]

**Mediator Approval:** pending

---

## Round 2

### Changes (Round 1)
- [What was implemented]

### Self-Review (Implementer)
[Implementer's own review of changes with H/M/L]

### External Review (Codex)
[Paste or summarize mcp__codex__codex-reply response with H/M/L labels]
- H: ...
- M: ...
- L: ...

### Reconciliation
| Issue | Self-Review | Codex | Agreement |
|-------|-------------|-------|-----------|

### Round 2 Synthesis

**Consensus:**
- ...

**Disagreements:**
- ...

**Actions:**
- [ ] ...

**Decision points:** none this round.

**Open Questions:**
- ...

**Gate Status:**
- Open high-severity items? [yes/no - must be no to close]
- Open medium items accepted? [yes/no/N/A]
- All actions addressed? [yes/no]
- Ready to close? [yes/no]

**Mediator Approval:** pending

---

## Final Synthesis
- Decision: ...
- Risks accepted: ...
- Next steps: ...

**Attestation:** I confirm this log reflects genuine review work, not template filling. - [NAME]
```

---

## Exemplars

Study these before consulting an outside expert:

- **skill-crafting** (`skills/skill-crafting/`) - Co-developed using this skill. Multi-round MCP sessions (threads `019bda94-d0c9-7c23-aae0-d4d933a2547d`, `019bdc86-502b-7ca1-97e9-814eaa7355dd`, `019bdc91-1ea3-71c3-ab8f-bda225806061`). Demonstrates severity progression H→M→L→clear, mid-flight fixes, dual-review pattern (self-review + external review + reconcile), convergence.

---

## Notes on Structure Emergence

Do not over-prescribe the format until you hit friction.
- If experts miss key areas, tighten the template.
- If output feels bloated, remove sections.
- If convergence is slow, add stricter stop conditions.

The structure should emerge from failure modes, not from theory.
